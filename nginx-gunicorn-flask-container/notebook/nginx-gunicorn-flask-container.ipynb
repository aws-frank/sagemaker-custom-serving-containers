{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Nginx Gunicorn Flask Serving Container</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to build and use a custom Docker container for serving with Amazon SageMaker that leverages on the serving stack provided by the sagemaker-containers library (Nginx-Gunicorn-Flask). Reference documentation is available at https://github.com/aws/sagemaker-containers.\n",
    "\n",
    "We will use this serving stack to serve an XGBoost model created from the Customer Churn SageMaker example available <a href=\"https://github.com/awslabs/amazon-sagemaker-examples/blob/master/introduction_to_applying_machine_learning/xgboost_customer_churn/xgboost_customer_churn.ipynb\">here</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by defining some variables like the current execution role, the ECR repository that we are going to use for pushing the custom Docker container and a default Amazon S3 bucket to be used by Amazon SageMaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "ecr_namespace = 'sagemaker-serving-containers/'\n",
    "prefix = 'nginx-gunicorn-flask-container'\n",
    "\n",
    "ecr_repository_name = ecr_namespace + prefix\n",
    "role = get_execution_role()\n",
    "account_id = role.split(':')[4]\n",
    "region = boto3.Session().region_name\n",
    "sagemaker_session = sagemaker.session.Session()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "print(account_id)\n",
    "print(region)\n",
    "print(role)\n",
    "print(bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the Dockerfile which defines the statements for building our serving container:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pygmentize ../docker/Dockerfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At high-level the Dockerfile specifies the following operations for building this container:\n",
    "\n",
    "<ul>\n",
    "    <li>Start from Python 3.7.3</li>\n",
    "    <li>Install nginx and other dependencies.</li>\n",
    "    <li>Install XGBoost.</li>\n",
    "    <li>Set e few environment variables, including PYTHONUNBUFFERED which is used to avoid buffering Python standard output (useful for logging)</li>\n",
    "    <li>Copy a .tar.gz package named <strong>nginx_gunicorn_flask_serving-1.0.0.tar.gz</strong> in the WORKDIR</li>\n",
    "    <li>Install this package.</li>\n",
    "    <li>Finally, set the value of the environment variable <strong>SAGEMAKER_SERVING_MODULE</strong> to a Python module defined in the package we installed.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Build and push the container</h3>\n",
    "We are now ready to build this container and push it to Amazon ECR. This task is executed using a shell script stored in the ../script/ folder. Let's take a look at this script and then execute it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pygmentize ../scripts/build_and_push.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>--------------------------------------------------------------------------------------------------------------------</h3>\n",
    "\n",
    "The script builds the Docker container, then creates the repository if it does not exist, and finally pushes the container to the ECR repository. The build task requires a few minutes to be executed the first time, then Docker caches build outputs to be reused for the subsequent build operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ../scripts/build_and_push.sh $account_id $region $ecr_repository_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Hosting with Amazon SageMaker</h3>\n",
    "\n",
    "Once we have correctly pushed our container to Amazon ECR, we are ready to deploy with Amazon SageMaker, which requires the ECR path to the Docker container used for serving as parameter for deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "container_image_uri = '{0}.dkr.ecr.{1}.amazonaws.com/{2}:latest'.format(account_id, region, ecr_repository_name)\n",
    "print(container_image_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, we need to provide XGBoost model artifacts. For the purpose of this example, we will deploy a regrssion model trained on the [Abalone data](https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/regression.html) originally from the [UCI data repository](https://archive.ics.uci.edu/ml/datasets/abalone).\n",
    "For further information, please refer to this [example](https://github.com/awslabs/amazon-sagemaker-examples/blob/master/introduction_to_amazon_algorithms/xgboost_abalone/xgboost_abalone.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_model_path = 's3://{0}/{1}/model/model.tar.gz'.format(bucket, prefix)\n",
    "!aws s3 cp model.tar.gz {s3_model_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To deploy our model, in addition to the container we need to provide the model location in Amazon S3 and the code that will be used to load this model and execute inferences.\n",
    "Using sagemaker-containers, the container is able to dynamically load the inference code from a package saved to Amazon S3. The Amazon SageMaker Python SDK is responsible to create this package (.tar.gz archive) and upload to S3 (**code_location**), given the entry point (**entry_point**) and a source directory (**source_dir**).\n",
    "\n",
    "In addition, we are passing a dictionary of variables that will be set as environment variables at run-time by the sagemaker-containers library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.model import FrameworkModel\n",
    "from time import gmtime, strftime\n",
    "\n",
    "model_name = 'nginx-gunicorn-flask-serving-' + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "\n",
    "s3_model_path = 's3://{0}/{1}/model/model.tar.gz'.format(bucket, prefix)\n",
    "s3_code_location = 's3://{0}/{1}/code'.format(bucket, prefix)\n",
    "\n",
    "model = FrameworkModel(name = model_name,\n",
    "                       model_data = s3_model_path,\n",
    "                       image_uri = container_image_uri,\n",
    "                       role=role,\n",
    "                       entry_point='predictor.py',\n",
    "                       source_dir='source_dir/',\n",
    "                       env = {\n",
    "                           'SAGEMAKER_USE_NGINX': 'true',\n",
    "                           'SAGEMAKER_MODEL_SERVER_WORKERS': '1',\n",
    "                           'SAGEMAKER_MODEL_SERVER_TIMEOUT': '300'\n",
    "                       },\n",
    "                       predictor_cls = sagemaker.predictor.Predictor,\n",
    "                       code_location=s3_code_location,\n",
    "                       #sagemaker_session=sagemaker_session #comment this line for local mode.\n",
    "                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the **SAGEMAKER_USE_NGINX** variable allows to enable or disable using nginx based on needs: if nginx is disabled, the inference endpoints will be exposed by gunicorn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name = 'nginx-gunicorn-flask-serving-ep-' + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "print(endpoint_name)\n",
    "\n",
    "pred = model.deploy(initial_instance_count=1,\n",
    "                    instance_type='local',\n",
    "                    endpoint_name=endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.predictor import Predictor\n",
    "pred.serializer = sagemaker.serializers.CSVSerializer()\n",
    "\n",
    "item = '77,33,143.0,101,212.2,102,104.9,120,15.3,4,5,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,1'\n",
    "pred.predict(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
